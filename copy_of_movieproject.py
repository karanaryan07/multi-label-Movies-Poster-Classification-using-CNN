# -*- coding: utf-8 -*-
"""Copy of MovieProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/karanaryan07/multi-label-Movies-Poster-Classification-using-CNN/blob/master/MovieProject.ipynb
"""

from google.colab import drive

drive.mount('/content/drive')

ls

cd 'drive'

cd 'My Drive'

ls

cd 'movie'

ls

!pip install tensorflow-gpu==2.0.0-rc0

import tensorflow as tf
from tensorflow.keras import Sequential

from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing import image

print(tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from tqdm import tqdm

!git clone https://github.com/laxmimerit/Movies-Poster_Dataset.git

data = pd.read_csv('/content/drive/My Drive/movie/Movies-Poster_Dataset/train.csv')

data.shape

data.head()

img_width = 350
img_height = 350

X = []

img_width = 350
img_height = 350

X = []

for i in tqdm(range(data.shape[0])):
  path = '/content/drive/My Drive/movie/Movies-Poster_Dataset/Images/' + data['Id'][i] + '.jpg'
  img = image.load_img(path, target_size=(img_width, img_height, 3))
  img = image.img_to_array(img)
  img = img/255.0
  X.append(img)

X = np.array(X)

X.shape

plt.imshow(X[2250])

y = data.drop(['Id', 'Genre'], axis = 1)
y = y.to_numpy()
y.shape

X_train , X_test , y_train , y_test =  train_test_split(X,y,random_state = 0,test_size = 0.15)
X_train[0].shape

model = Sequential()
model.add(Conv2D(16, (3,3), activation='relu', input_shape = X_train[0].shape))
model.add(BatchNormalization())
model.add(MaxPool2D(2,2))
model.add(Dropout(0.3))

model.add(Conv2D(32, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(2,2))
model.add(Dropout(0.3))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(2,2))
model.add(Dropout(0.4))

model.add(Conv2D(128, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(2,2))
model.add(Dropout(0.5))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))


model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))


model.add(Dense(25, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))

def plot_learningCurve(history, epoch):
  # Plot training & validation accuracy values
  epoch_range = range(1, epoch+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

  # Plot training & validation loss values
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

plot_learningCurve(history, 5)

img = image.load_img('/content/drive/My Drive/movie/Movies-Poster_Dataset/fast.jpg', target_size=(img_width, img_height, 3))
plt.imshow(img)
img = image.img_to_array(img)
img = img/255.0

img = img.reshape(1, img_width, img_height, 3)
#classes = data.columns[2:]
#print(classes)
Y_prob = model.predict(img)
top3 = np.argsort(Y_prob[0])[:-4 :-1]
for i in range(3):
  print(classes[top3[i]])



